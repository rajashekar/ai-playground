{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d0680c-f8a2-4846-aafa-efebb94d11ad",
   "metadata": {},
   "source": [
    "# Summarize pdf content using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7128e-9f45-4f62-9089-dc70c9550b36",
   "metadata": {},
   "source": [
    "## Set openai api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0632e6c1-e517-4eb6-9290-ea999d28843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "openai_api_key = getpass.getpass(\"OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b3adfd-865e-40a7-9a10-b2910c9061fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c6a30e-28f1-4469-9666-921fd8d3e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be17043-0390-42b4-88e2-250e5f855037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "144f387e-b843-48ae-bdd1-881a66f7f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHello there! It looks like you are trying out a test. How is it going so far?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"hello, this is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88287a00-74cd-4529-a196-76806aae521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c433c8f-4bbc-44fc-9155-48d396c0b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "This is a great test! It looks like you are trying to determine if the message is readable. If so, congratulations! The message is readable and understandable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm(\"hello, this is a test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bb3490-c9c5-4674-80ff-390252cec2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qqq pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370f894-e41f-4fc4-8cb0-e9be8571f802",
   "metadata": {},
   "source": [
    "## Read pdf content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6778de48-0168-4cf7-82f6-da951f3ae168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./embeddings.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60052a71-50fe-4fe8-a67c-4051dda47d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd63497d-b6d8-48e9-bb33-e7fc4471dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\\n\\n\".join([page.page_content for page in pages[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "374635c9-78b2-408b-9904-0753768b9be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1 Introduction\n",
       "Implementing deep learning models has become an increasingly important\n",
       "machine learning strategy1for companies looking to build data-driven prod-\n",
       "ucts. In order to build and power deep learning models, companies collect and\n",
       "feed hundreds of millions of terabytes of multimodal2data into deep learning\n",
       "models. As a result, embeddings — deep learning models’ internal represen-\n",
       "tations of their input data — are quickly becoming a critical component of\n",
       "building machine learning systems.\n",
       "For example, they make up a significant part of Spotify’s item recom-\n",
       "mender systems [ 27], YouTube video recommendations of what to watch [ 11],\n",
       "and Pinterest’s visual search [ 31]. Even if they are not explicitly presented\n",
       "to the user through recommendation system UIs, embeddings are also used\n",
       "internally at places like Netflix to make content decisions around which shows\n",
       "to develop based on user preference popularity.\n",
       "Figure 1: Left to right: Products that use embeddings used to generate recommended items:\n",
       "Spotify Radio, YouTube Video recommendations, visual recommendations at Pinterest, BERT\n",
       "Embeddings in suggested Google search results\n",
       "The usage of embeddings to generate compressed, context-specific repre-\n",
       "sentations of content exploded in popularity after the publication of Google’s\n",
       "Word2Vec paper [47].\n",
       "1Check out the machine learning industrial view Matt Turck puts together every year, which\n",
       "has exploded in size.\n",
       "2Multimodal means a variety of data usually including text, video, audio, and more recently\n",
       "as shown in Meta’s ImageBind, depth, thermal, and IMU.\n",
       "4\n",
       "\n",
       "Figure 2: Embeddings papers in Arxiv by month. It’s interesting to note the decline in\n",
       "frequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\n",
       "architectures like GPT source\n",
       "Building and expanding on the concepts in Word2Vec, the Transformer\n",
       "[66] architecture, with its self-attention mechanism, a much more specialized\n",
       "case of calculating context around a given word, has become the de-facto\n",
       "way to learn representations of growing multimodal vocabularies, and its rise\n",
       "in popularity both in academia and in industry has caused embeddings to\n",
       "become a staple of deep learning workflows.\n",
       "However, the concept of embeddings can be elusive because they’re neither\n",
       "data flow inputs or output results - they are intermediate elements that live\n",
       "within machine learning services to refine models. So it’s helpful to define\n",
       "them explicitly from the beginning.\n",
       "As a general definition, embeddings are data that has been transformed\n",
       "into n-dimensional matrices for use in deep learning computations. The\n",
       "process of embedding (as a verb):\n",
       "•Transforms multimodal input into representations that are easier to\n",
       "perform intensive computation on, in the form of vectors , tensors, or\n",
       "graphs [ 51]. For the purpose of machine learning, we can think of\n",
       "vectors as a list (or array) of numbers.\n",
       "•Compresses input information for use in a machine learning task — the\n",
       "type of methods available to us in machine learning to solve specific\n",
       "problems — such as summarizing a document or identifying tags or\n",
       "labels for social media posts or performing semantic search on a large\n",
       "text corpus. The process of compression changes variable feature\n",
       "dimensions into fixed inputs, allowing them to be passed efficiently\n",
       "into downstream components of machine learning systems.\n",
       "•Creates an embedding space that is specific to the data the embeddings\n",
       "were trained on but that, in the case of deep learning representations,\n",
       "can also generalize to other tasks and domains through transfer\n",
       "learning — the ability to switch contexts — which is one of the\n",
       "reasons embeddings have exploded in popularity across machine\n",
       "learning applications\n",
       "5\n",
       "\n",
       "What do embeddings actually look like? Here is one single embedding,\n",
       "also called a vector , in three dimensions . We can think of this as a repre-\n",
       "sentation of a single element in our dataset. For example, this hypothetical\n",
       "embedding represents a single word \"fly\", in three dimensions. Generally, we\n",
       "represent individual embeddings as row vectors.\n",
       "\u0002\n",
       "1 4 9\u0003\n",
       "(1)\n",
       "And here is a tensor , also known as a matrix3, which is a multidimensional\n",
       "combination of vector representations of multiple elements. For example, this\n",
       "could be the representation of \"fly\", and \"bird.\"\n",
       "\u00141 4 9\n",
       "4 5 6\u0015\n",
       "(2)\n",
       "These embeddings are the output of the process of learning embeddings,\n",
       "which we do by passing raw input data into a machine learning model. We\n",
       "transform that multidimensional input data by compressing it, through the\n",
       "algorithms we discuss in this paper, into a lower-dimensional space. The\n",
       "result is a set of vectors in an embedding space.\n",
       "Word\n",
       "Sentence\n",
       "ImageMultimodal data\n",
       "[1, 4, 9 ]\n",
       "[1, 4, 7 ]\n",
       "[12, 0, 3 ]Embedding Space\n",
       "Algorithm\n",
       "Figure 3: The process of embedding.\n",
       "We often talk about item embeddings being in Xdimensions, ranging\n",
       "anywhere from 100 to 1000, with diminishing returns in usefulness somewhere\n",
       "beyond 200-300 in the context of using them for machine learning problems4.\n",
       "This means that each item (image, song, word, etc) is represented by a vector\n",
       "of length X, where each value is a coordinate in an X-dimensional space.\n",
       "We just made up an embedding for \"bird\", but let’s take a look at what a\n",
       "real one for the word \"hold\" would look like in the quote, as generated by the\n",
       "BERT deep learning model,\n",
       "\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\n",
       "cannot fly.\" — Langston Hughes\n",
       "We’ve highlighted this quote because we’ll be working with this sentence\n",
       "as our input example throughout this text.\n",
       "3The difference between a matrix and a tensor is that it’s a matrix if you’re doing linear\n",
       "algebra and a tensor if you’re an AI researcher.\n",
       "4Embedding size is tunable as a hyperparameter but so far there have only been a few\n",
       "papers on optimal embedding size, with most of the size of embeddings set through magic and\n",
       "guesswork\n",
       "6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5744370-7f6c-4f03-a61f-0c6a521c6edf",
   "metadata": {},
   "source": [
    "## Summarize above content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1116647d-d720-4d7e-8ac8-1d31be648634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Embeddings are a way of transforming data (e.g. text, images, audio, etc) into numerical representations that can be used for machine learning algorithms. Embeddings are often represented as vectors, tensors, or graphs, and are used to compress input information and create an embedding space which is specific to the data they have been trained on. They can also generalize to other tasks and domains using transfer learning. Embeddings are typically set to a size of 100-1000, where each value is a coordinate in a multidimensional space."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm(f\"\"\"Summarize below content:\n",
    "{content}\"\"\")\n",
    "\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b162d80-6327-4482-bed1-bae3c3002bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
